{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72a02d8-0321-4f5d-8609-2c5ea66ea922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33ec69-fd9e-41d6-a220-66fabc6eb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save PassengerId for submission\n",
    "test_passenger_ids = test_df[\"PassengerId\"].copy()\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39a54a-4728-423d-acc0-c241771c4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PREPROCESSING FUNCTION ====================\n",
    "def preprocess_data(df, is_train=True):\n",
    "    \"\"\"Preprocess train or test data with same transformations\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle Cabin Column\n",
    "    df[[\"deck\",\"num\",\"side\"]] = df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = [\"PassengerId\", \"Name\", \"Cabin\"]\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Convert num to numeric\n",
    "    df['num'] = pd.to_numeric(df['num'], errors='coerce')\n",
    "    \n",
    "    # Fill missing values for numerical columns\n",
    "    num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"num\"]\n",
    "    for col in num_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Fill missing values for categorical columns with mode\n",
    "    cat_cols = [\"CryoSleep\", \"Destination\", \"VIP\", \"deck\", \"side\"]\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            mode_val = df[col].mode()\n",
    "            if len(mode_val) > 0:\n",
    "                df[col] = df[col].fillna(mode_val.iloc[0])\n",
    "\n",
    " # Fill HomePlanet based on deck\n",
    "    if 'HomePlanet' in df.columns and 'deck' in df.columns:\n",
    "        df['HomePlanet'] = df.groupby('deck')['HomePlanet'].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else 'Earth')\n",
    "        )\n",
    "    \n",
    "    # Create services feature\n",
    "    service_cols = [\"ShoppingMall\", \"RoomService\", \"FoodCourt\", \"Spa\", \"VRDeck\"]\n",
    "    df[\"services\"] = df[service_cols].sum(axis=1)\n",
    "    df.drop(service_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Remove outliers (only for training data)\n",
    "    if is_train:\n",
    "        for col in [\"Age\", \"services\"]:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5*IQR\n",
    "            upper = Q3 + 1.5*IQR\n",
    "            df[col] = df[col].clip(lower, upper)\n",
    "    \n",
    "    # One-hot encoding\n",
    "    encode_cols = [\"HomePlanet\", \"Destination\", \"deck\", \"side\"]\n",
    "    df = pd.get_dummies(columns=encode_cols, data=df, drop_first=True, dtype=int)\n",
    "    \n",
    "    # Convert boolean to int\n",
    "    bool_cols = [\"CryoSleep\", \"VIP\"]\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81747b-b1a9-4551-80e8-09e17dfe2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train features shape: (8693, 17)\n",
      "Test features shape: (4277, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/1mq4g7t165x1k9x384n7wht40000gn/T/ipykernel_36990/541832270.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(mode_val.iloc[0])\n",
      "/var/folders/c6/1mq4g7t165x1k9x384n7wht40000gn/T/ipykernel_36990/541832270.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(mode_val.iloc[0])\n"
     ]
    }
   ],
   "source": [
    "stitanic = preprocess_data(train_df, is_train=True)\n",
    "test_processed = preprocess_data(test_df, is_train=False)\n",
    "\n",
    "# Separate target variable\n",
    "y = stitanic[\"Transported\"].astype(int)\n",
    "X = stitanic.drop(\"Transported\", axis=1)\n",
    "\n",
    "# Align test data columns with train data\n",
    "# Add missing columns to test with 0 values\n",
    "for col in X.columns:\n",
    "    if col not in test_processed.columns:\n",
    "        test_processed[col] = 0\n",
    "\n",
    "# Remove extra columns from test\n",
    "test_processed = test_processed[X.columns]\n",
    "\n",
    "print(\"\\nTrain features shape:\", X.shape)\n",
    "print(\"Test features shape:\", test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10937f74-c982-42c0-adeb-1d1dd59d8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: (6085, 17)\n",
      "Validation set: (1304, 17)\n",
      "Internal test set: (1304, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_val, X_test_internal, y_val, y_test_internal = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)\n",
    "\n",
    "print(\"\\nTrain set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Internal test set:\", X_test_internal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LightGBM \n",
    "print(\"\\n1. LightGBM\")\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "y_val_pred = lgb_model.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\n2. Random Forest\")\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf):.4f}\")\n",
    "\n",
    "# 3. AdaBoost\n",
    "print(\"\\n3. AdaBoost\")\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_val_pred_ada = ada_model.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_ada):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508be5b-e060-458e-8f8b-9a75978643f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LightGBM\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3069, number of negative: 3016\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 6085, number of used features: 16\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504355 -> initscore=0.017420\n",
      "[LightGBM] [Info] Start training from score 0.017420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Validation Accuracy: 0.7630\n",
      "\n",
      "2. Random Forest\n",
      "Validation Accuracy: 0.7707\n",
      "\n",
      "3. AdaBoost\n",
      "Validation Accuracy: 0.7546\n",
      "\n",
      "==================================================\n",
      "TRAINING FINAL MODEL ON FULL DATA\n",
      "==================================================\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3712, number of negative: 3677\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 7389, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502368 -> initscore=0.009474\n",
      "[LightGBM] [Info] Start training from score 0.009474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Internal Test Accuracy: 0.7692\n",
      "\n",
      "==================================================\n",
      "GENERATING SUBMISSION FILE\n",
      "==================================================\n",
      "\n",
      "✓ Submission file 'submission.csv' created successfully!\n",
      "✓ Shape: (4277, 2)\n",
      "\n",
      "First few predictions:\n",
      "  PassengerId  Transported\n",
      "0     0013_01         True\n",
      "1     0018_01        False\n",
      "2     0019_01         True\n",
      "3     0021_01        False\n",
      "4     0023_01        False\n",
      "5     0027_01        False\n",
      "6     0029_01         True\n",
      "7     0032_01         True\n",
      "8     0032_02         True\n",
      "9     0033_01        False\n",
      "\n",
      "Prediction distribution:\n",
      "Transported\n",
      "False    2432\n",
      "True     1845\n",
      "Name: count, dtype: int64\n",
      "Percentage Transported: 43.14%\n"
     ]
    }
   ],
   "source": [
    "# ==================== CHOOSE BEST MODEL ====================\n",
    "# Let's use LightGBM as it typically performs best\n",
    "# Train on full dataset (train + val) for final submission\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING FINAL MODEL ON FULL DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "final_model = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "# Evaluate on internal test set\n",
    "y_test_pred = final_model.predict(X_test_internal)\n",
    "print(f\"Internal Test Accuracy: {accuracy_score(y_test_internal, y_test_pred):.4f}\")\n",
    "\n",
    "# ==================== GENERATE SUBMISSION ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GENERATING SUBMISSION FILE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make predictions on actual test data\n",
    "test_predictions = final_model.predict(test_processed)\n",
    "\n",
    "# Convert to boolean as required by competition\n",
    "test_predictions_bool = test_predictions.astype(bool)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Transported': test_predictions_bool\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\n✓ Submission file 'submission.csv' created successfully!\")\n",
    "print(f\"✓ Shape: {submission.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Display prediction distribution\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['Transported'].value_counts())\n",
    "print(f\"Percentage Transported: {submission['Transported'].sum() / len(submission) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029250e5-1fe4-42a3-bb19-93ff187c11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
